\section*{Classification and regression trees (CART)}
$y_i = \sum_{r=1}^M \beta_r \mathds{1}_{x_i\in R_r} + \epsilon_i$.
where $\mathcal{P}=\{R_1,...,R_M\}$ is a partition of $\mathbb{R}^p$.
If the partition is given, estimation is easy: $\hat\beta_j =\tfrac{\sum_{i=1}^n Y_i 1_{x_i\in R_j}}{\sum_{i=1}^n 1_{x_i\in R_j}}=$ average $y$ value among obs. in $R_j$.

\textbf{Recursive Binary Splitting:} Greedy method to find the regions:
For all predictors find the best cutting point, then take the cutting point that minimizes the error $\sum_{i: x\in R_1} (y_i - \bar y_{R_1})^2 + \sum_{i: x \in R_2} (y_i - \bar y_{R_2})^2$.
Stop when region contains less than 5 elements.

\textbf{Pruning:} A deep tree $T_0$ can overfit.
Pruning is a possible solution:
For $\alpha >0$: find $\text{argmin}_{T\subset T_0} err(T) + \alpha |T|$.
$\alpha$ is tuning parameter, find via CV: Apply cost complexity pruning to the large tree to obtain a seq. of best subtrees as a function of $\alpha$.
Use K-fold CV to choose $\alpha$, i.e. for $k=1,..., K$: on all but $k$-th fold make a tree and prune it back for same $\alpha$'s as above, evaluate MSE on $k$-th fold.
Average for each value of $\alpha$ and pick minimizing $\alpha$.
Return the subtree of the full tree corresponding to minimal $\alpha$.

\textbf{Classification Trees:}
At each split, try to improve node purity measured by gini index: $I(D) = [\tfrac{n_L}{n} I(D_L) + \tfrac{n_R}{n} I(D_R)] > 0$ where the subtrees are $I(D_R) = \hat p (1-\hat p)$ where $\hat p = \tfrac{\#yes}{\#yes + \#no}$. Can predict class probability $\hat p_k(x) = \textit{proportion of observations with class }k\textit{ in leaf node that contains }x$.

\begin{codebox}{r}{Using Trees}
  # Create and plot tree
  library(tree)
  cs.tree <- tree(Sales ~ . , \textit{train_data})
  plot(cs.tree); text(cs.tree, pretty=1)
  # Predict using tree, type="class" for classification
  test.pred <- predict(cs.tree, \textit{test_data})
  (MSE <- mean((test.data$Sales - test.pred)^2))
    # Prune tree. FUN=prune.misclass, $dev for nr. of misclassifications
  cv.carseats = cv.tree(cs.tree, FUN=prune.tree)
  best.size <- cv.carseats$size [which.min(cv.carseats$dev)]
  pruned.tree <- prune.tree(cs.tree, best = best.size)
\end{codebox}
